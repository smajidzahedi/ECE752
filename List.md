### List of suggested related papers (adapted from [CS886 - Multiagent Systems](https://cs.uwaterloo.ca/~klarson/teaching/W25-886/) and [CS15-888 - Computational Game Solving](https://www.cs.cmu.edu/~sandholm/cs15-888F25/)):

- *Combining Deep Reinforcement Learning and Search for Imperfect-Information Games*, Brown et al. [NeurIPS 2020](arxiv.org/pdf/2007.13544)

- *Grandmaster level in StarCraft II using multi-agent reinforcement learning*, Vinyals et al. [Nature 2019](www.nature.com/articles/s41586-019-1724-z)

- *Superhuman AI for heads-up no-limit poker: Libratus beats top professionals*, Brown and Sandholm [Science 2018]

- *No-Regret Learning in Convex Games*, Gordon et al. [ICML 2008](https://www.cs.cmu.edu/~ggordon/gordon-greenwald-marks-icml-phi-regret.pdf)

- *Social Norm Complexity and Past Reputations in the Evolution of Cooperation*, Santos et al. [Nature 2018](https://www.nature.com/articles/nature25763)

- *Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents*, Piatti et al. [NeurIPS 2024](https://neurips.cc/virtual/2024/poster/96895)

- *Learning with Opponent Learning Awareness*, Foerster et al. [AAMAS 2018](https://www.ifaamas.org/Proceedings/aamas2018/pdfs/p122.pdf)

- *Inequity aversion improves cooperation in intertemporal social dilemmas*, Hughes et al. [NeurIPS 2018](https://proceedings.neurips.cc/paper/2018/file/7fea637fd6d02b8f0adf6f7dc36aed93-Paper.pdf)

- *Theory of Minds: Understanding Behavior in Groups through Inverse Planning*, Shum et al. [AAAI 2019](https://arxiv.org/abs/1901.06085)

- *The AI Economist: Taxation policy design via two-level deep multiagent reinforcement learning*, Zheng et al. [Science 2021](https://www.science.org/doi/10.1126/sciadv.abk2607)

- *Human-level play in the game of Diplomacy*, combining language models with strategic reasoning*, Bakhtin et al. [Science 2022](https://www.science.org/doi/10.1126/science.ade9097)

- *STEER: Assessing the Economic Rationality of Large Language Models*, Raman et al. [ICML 2024](https://icml.cc/virtual/2024/poster/33120)

- *The Good Shepherd: An Oracle Agent for Mechanism Design*, Balaguer et al [arXiv 2022](https://arxiv.org/abs/2202.10135)

- *Mechanism Design for Large Language Models*, Duetting et al. [WWW 2024](https://dl.acm.org/doi/10.1145/3589334.3645511)

- *Generative Social Choice*, Fish et al. [ACM EC 2024](https://arxiv.org/abs/2309.01291)

- *AI can Help Humans Find Common Ground in Democratic Deliberation*, Tessler et al. [Science 2024](https://www.science.org/doi/10.1126/science.adq2852)

- *Constitutional AI: Harmlessness from AI Feedback*, Bai et al. [arXiv 2022](https://arxiv.org/abs/2212.08073)

- *Fine-Tuning Language Models from Human Preferences*, Ziegler et al [arXiv 2020](https://arxiv.org/abs/1909.08593)

- *Direct Preference Optimization: Your Language Model is Secretly a Reward Model*, Rafailov et al [arXiv 2023](https://arxiv.org/abs/2305.18290)

- *Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF*, Siththaranjan et al. [ICLR 2024](https://arxiv.org/abs/2312.08358)

- *Nash Learning from Human Feedback*, Munos et al. [ICML 2024](https://arxiv.org/abs/2312.00886)

- *A Roadmap to Pluralistic Alignment*, Sorensen et al. [ICML 2024](https://arxiv.org/abs/2402.05070)

- *Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback*, Conitzer et al. [ICML 2024](https://arxiv.org/abs/2404.10271)

### You can also check the following GitHub page for more related papers:
- [Awesome-AgenticLLM-RL-Papers](https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers)
- [MARL-Papers](https://github.com/LantaoYu/MARL-Papers)
- [awesome-LLM-game-agent-papers](https://github.com/git-disl/awesome-LLM-game-agent-papers)
